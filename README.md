In this text summarization project, I aimed to develop an effective and versatile system for condensing large bodies of text into concise summaries, catering to the increasing demand for efficient information processing. Leveraging advanced natural language processing techniques and pre-trained models, I employed the BART (Bidirectional and Auto-Regressive Transformers) architecture for conditional text generation. Key evaluation metrics such as BLEU and ROUGE scores were computed to assess the model's summarization performance, providing insights into the system's ability to generate accurate and coherent summaries. Additionally, the project featured a web-based interface that allowed users to interact with the summarization system, showcasing its practical utility.
This project not only contributes to the field of natural language processing by showcasing the effectiveness of transformer-based models in text summarization but also underscores the broader applications of such technologies in real-world scenarios. The combination of state-of-the-art models, rigorous evaluation methodologies, and user-friendly interfaces positions this project as a valuable tool for professionals and researchers seeking to streamline information consumption, making it particularly relevant in contexts where the quick extraction of salient information from extensive texts is crucial. The successful implementation and evaluation of this text summarization system highlight its potential for various domains, including journalism, research, and content curation, marking a step forward in advancing the capabilities of automated summarization technologies.
Along with the implementation of the text summarization app, I have tried to fine-tune the pre-trained model with CCN-Daily News which has 300k unique samples, but I couldnâ€™t. My system which runs only the CPU is unable to tokenize the dataset and I have tried other datasets also; I found the same issue unable to tokenize the dataset which terminates indefinitely. 
